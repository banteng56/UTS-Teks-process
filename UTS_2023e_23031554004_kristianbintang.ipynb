{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPPING DATA KEYWORD VIDEOGAMES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Membuka file CSV untuk menulis data\n",
    "with open('springer_videogames.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Title', 'Link', 'Publication Date', 'Authors', 'Abstract'])\n",
    "    \n",
    "    for page in range(1, 6):  # Mengambil halaman 1 hingga 5\n",
    "        print(f\"Scraping halaman {page}...\")\n",
    "        \n",
    "        # URL pencarian di SpringerLink dengan pagination\n",
    "        url = f\"https://link.springer.com/search?new-search=true&query=videogames&content-type=Article&sortBy=relevance&page={page}\"\n",
    "        \n",
    "        # Headers untuk menyamarkan request agar terlihat seperti dari browser\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Mencari elemen <li> yang memiliki class \"app-card-open\"\n",
    "            articles = soup.find_all('li', {'class': 'app-card-open'})\n",
    "            \n",
    "            for article in articles:\n",
    "                # Mengambil judul artikel\n",
    "                title_tag = article.find('a', {'class': 'app-card-open__link'})\n",
    "                title = title_tag.text.strip() if title_tag else 'N/A'\n",
    "                \n",
    "                # Mengambil link artikel\n",
    "                article_link = f\"https://link.springer.com{title_tag['href']}\" if title_tag else 'N/A'\n",
    "                \n",
    "                # Mengambil tanggal publikasi\n",
    "                date_tag = article.find('span', {'class': 'c-meta__item', 'data-test': 'published'})\n",
    "                publish_date = date_tag.text.strip() if date_tag else 'N/A'\n",
    "                \n",
    "                # Mengambil nama penulis dan abstrak dari halaman artikel\n",
    "                authors = []\n",
    "                abstract = 'N/A'\n",
    "                \n",
    "                if article_link != 'N/A':\n",
    "                    article_response = requests.get(article_link, headers=headers)\n",
    "                    if article_response.status_code == 200:\n",
    "                        article_soup = BeautifulSoup(article_response.text, 'html.parser')\n",
    "                        \n",
    "                        # Mengambil nama penulis\n",
    "                        author_tags = article_soup.find_all('a', {'data-test': 'author-name'})\n",
    "                        authors = [author.text.strip() for author in author_tags]\n",
    "                        \n",
    "                        # Mengambil abstrak\n",
    "                        abstract_tag = article_soup.find('section', {'data-title': 'Abstract'})\n",
    "                        if abstract_tag:\n",
    "                            abstract_content = abstract_tag.find('p')\n",
    "                            abstract = abstract_content.text.strip() if abstract_content else 'N/A'\n",
    "\n",
    "                writer.writerow([title, article_link, publish_date, ', '.join(authors), abstract])\n",
    "        else:\n",
    "            print(f\"Gagal mengakses halaman {page}, status code: {response.status_code}\")\n",
    "\n",
    "print(\"Data berhasil disimpan ke 'springer_videogames.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "df = pd.read_csv('springer_videogames.csv')\n",
    "\n",
    "# Daftar normalisasi singkatan\n",
    "abbreviation_mapping = {\n",
    "    \"sps\": \"social problem solving\",\n",
    "    \"scm\": \"supply chain management\",\n",
    "    \"dsc\": \"digital supply chain\",\n",
    "    \"covid\": \"coronavirus disease\",\n",
    "    \"pisa\": \"programme for international student assessment\",\n",
    "    \"asd\": \"autism spectrum disorder\",\n",
    "    \"pass\": \"planning attention simultaneous successive\",\n",
    "    \"tv\": \"television\",\n",
    "    \"pls\": \"partial least squares\",\n",
    "    \"baq\": \"body appreciation questionnaire\",\n",
    "    \"uk\": \"united kingdom\",\n",
    "    \"us\": \"united states\",\n",
    "    \"bmi\": \"body mass index\",\n",
    "    \"npc\": \"non-playable character\",\n",
    "    \"vr\": \"virtual reality\",\n",
    "    \"icd\": \"international classification of diseases\",\n",
    "    \"igdt\": \"internet gaming disorder test\",\n",
    "    \"sd\": \"standard deviation\",\n",
    "    \"mako\": \"makoplasty\",\n",
    "    \"sf\": \"science fiction\",\n",
    "    \"ci\": \"confidence interval\",\n",
    "    \"prisma\": \"preferred reporting items for systematic reviews and meta-analyses\",\n",
    "    \"robust\": \"reliable and objectively measured\",\n",
    "    \"cpv\": \"child physical violence\",\n",
    "    \"cinahl\": \"cumulative index to nursing and allied health literature\",\n",
    "    \"pc\": \"personal computer\",\n",
    "    \"igd\": \"internet gaming disorder\",\n",
    "    \"piu\": \"problematic internet use\",\n",
    "    \"gd\": \"generalized disorder\",\n",
    "    \"er\": \"emergency room\",\n",
    "    \"sr\": \"systematic review\",\n",
    "    \"ed\": \"eating disorder\",\n",
    "    \"medline\": \"medical literature analysis and retrieval system online\",\n",
    "    \"ucc\": \"universal credit center\",\n",
    "    \"vasc\": \"vascular\",\n",
    "    \"insee\": \"national institute of statistics and economic studies\",\n",
    "    \"nuts\": \"nomenclature of territorial units for statistics\",\n",
    "    \"lra\": \"latent response analysis\",\n",
    "    \"hexaco\": \"hexaco personality inventory\",\n",
    "    \"ai\": \"artificial intelligence\",\n",
    "    \"ml\": \"machine learning\",\n",
    "    \"aim\": \"artificial intelligence in medicine\",\n",
    "    \"ri\": \"response inhibition\",\n",
    "    \"clpm\": \"cross-lagged panel model\",\n",
    "    \"or\": \"odds ratio\",\n",
    "    \"ses\": \"socioeconomic status\",\n",
    "    \"sias\": \"social interaction anxiety scale\",\n",
    "    \"brs\": \"brief resilience scale\",\n",
    "    \"scms\": \"supply chain management systems\",\n",
    "    \"fps\": \"first-person shooter\",\n",
    "    \"fc\": \"factorial complexity\",\n",
    "    \"bci\": \"brain-computer interface\",\n",
    "    \"pl\": \"psycholinguistics\",\n",
    "    \"hmd\": \"head-mounted display\",\n",
    "    \"ptsd\": \"post-traumatic stress disorder\",\n",
    "    \"ppd\": \"postpartum depression\",\n",
    "    \"gad\": \"generalized anxiety disorder\",\n",
    "    \"epds\": \"edinburgh postnatal depression scale\",\n",
    "    \"dsm\": \"diagnostic and statistical manual of mental disorders\",\n",
    "    \"ivr\": \"immersive virtual reality\",\n",
    "    \"boxvr\": \"a specific vr fitness game\",\n",
    "    \"hrv\": \"heart rate variability\",\n",
    "    \"hr\": \"heart rate\",\n",
    "    \"sdnn\": \"standard deviation of normal-to-normal intervals\",\n",
    "    \"acm\": \"association for computing machinery\",\n",
    "    \"gps\": \"global positioning system\",\n",
    "    \"crf\": \"cardiorespiratory fitness\",\n",
    "    \"iq\": \"intelligence quotient\"\n",
    "}\n",
    "\n",
    "# Fungsi untuk mengganti singkatan dengan kata lengkap di kolom 'Abstract'\n",
    "def normalize_abbreviations(text):\n",
    "    for abbr, full_form in abbreviation_mapping.items():\n",
    "        text = re.sub(r'\\b' + re.escape(abbr) + r'\\b', full_form, text)\n",
    "    return text\n",
    "\n",
    "# 1. Menangani nilai kosong di kolom 'Abstract'\n",
    "df['Abstract'] = df['Abstract'].fillna('')\n",
    "\n",
    "# 2. Normalisasi teks di kolom 'Abstract' (ubah menjadi huruf kecil)\n",
    "df['Preprocess Abstract'] = df['Abstract'].str.lower()\n",
    "\n",
    "# 3. Mengganti singkatan dengan bentuk lengkapnya\n",
    "df['Preprocess Abstract'] = df['Preprocess Abstract'].apply(normalize_abbreviations)\n",
    "\n",
    "# 4. Membersihkan teks di kolom 'Preprocess Abstract' (menghapus karakter khusus tetapi mempertahankan kata dan spasi)\n",
    "df['Preprocess Abstract'] = df['Preprocess Abstract'].apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n",
    "\n",
    "# 5. Menghapus stopword dari kolom 'Preprocess Abstract'\n",
    "stopwords = set(ENGLISH_STOP_WORDS)\n",
    "df['Preprocess Abstract'] = df['Preprocess Abstract'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stopwords])\n",
    ")\n",
    "\n",
    "\n",
    "output_path = 'springer_videogames_dengan_preprocessing.csv'\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv('springer_videogames_dengan_preprocessing.csv')\n",
    "\n",
    "texts = df['Preprocess Abstract'].fillna('')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Mengambil 1000 fitur teratas berdasarkan frekuensi kata\n",
    "\n",
    "# Transformasikan teks menjadi matriks TF-IDF\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "# Konversi hasil TF-IDF ke dalam DataFrame dengan fitur (kata) sebagai kolom\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "output_path = 'springer_videogames_tfidf_features.csv'\n",
    "tfidf_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Hasil TF-IDF telah disimpan di {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
